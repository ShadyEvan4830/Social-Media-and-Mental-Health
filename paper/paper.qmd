---
title: "Welfare Expectations Across U.S. Economic Cycles"
subtitle: "Analysis of the the American public's views on government provision of benefits under different economic conditions over the past 50 years"
author: 
  - Tianen (Evan) Hao
thanks: "Code and data are available at: https://github.com/ShadyEvan4830/Welfare_Expectations_and_The_Economy.git."
date: March 31, 2024
date-format: long
abstract: "A country's economic conditions often influence public perceptions of government welfare practices. However, do all citizens truly meet the general expectation of higher welfare during economic downturns and lower welfare during economic boom? Using data from the General Social Survey (GSS) Welfare, this paper examines whether the American public believes government welfare initiatives have been adequate over the past 50 years, particularly under different economic circumstances. Our analysis shows that there are widespread public calls to reduce welfare spending during good times, while in bad times, this leads to a stronger demand for government assistance. Despite this trend, journal research shows that differences in welfare expectations remain evident between different demographic groups, such as high and low-income groups. This finding highlights the need for society to develop welfare policies for different groups and provide a basis for creating fairer and more sensitive welfare strategies amid economic fluctuations."
format: pdf
toc: true
number-sections: true
bibliography: bibliography.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#download the packages if necessary, then load the packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(janitor,here,dplyr,tidyverse,knitr,kableExtra,ggplot2)

library(janitor)
library(tidyverse)
library(knitr)
library(dplyr)
library(kableExtra)
library(here)
library(ggplot2)
```

# Introduction {#sec-intro}

Public attitudes towards government welfare programs fluctuate with economic conditions, swinging from calls for austerity during prosperous times to demands for increased support in downturns. This study investigates whether there is a consistent trend of advocating for reduced welfare spending in periods of economic prosperity and whether there's a noticeable shift towards supporting more government welfare provisions during downturns, as seen during the 1982 recession and the 2020 COVID-19 pandemic. Importantly, we explore whether this trend is consistent across all public segments or if attitudes vary among different demographic groups through various journal research.

This paper uses nearly 50 years of welfare data from the General Social Survey (GSS) to study the U.S. economic situation and public perceptions of welfare adequacy. We analyze public opinion primarily during periods of growth, stability, and recession to identify overall trends in welfare perceptions and their impact on demographics defined by income and employment status.

We hypothesize that the public expects more benefits when the economy is low and fewer benefits when the economy is growing. The estimand is the difference in public support for increased welfare benefits if the economy were in a recession, as opposed to if the economy were experiencing growth. This is assessed through the lens of varying response groups to understand if the demand for greater welfare support is a ubiquitous response to economic hardship. Our preliminary findings show that public opinion is multifaceted. The recession significantly affected demand for increased government welfare action but with significant differences across demographic groups; different incomes or other social factors will significantly affect people's views on welfare. In addition to this we have seen a growing demand in recent years for perceived welfare needs to be enhanced.

These findings have profound implications, indicating that a one-size-fits-all approach to welfare policy may not effectively meet the population's diverse needs. Our research points to the benefits of developing welfare policies that are more responsive and tailored to the varied expectations and needs across the societal spectrum.

The structure of this paper starts with the current [Introduction] to explain the overall logic and content. The subsequent [Data] section outlines our methods and data-cleaning efforts. In the [Model] section, we use a linear regression model to further analyze the number of public responses to "too little" of welfare since 1972. The [Results] section presents findings on public welfare perceptions under different economic conditions. In [Discussion], we interpreted within the larger context of welfare policy and public expectations and are expected to trigger reflections on the study's limitations and potential directions for future research. Finally, we synthesize our main insights in [Conclusion] to highlight the urgent need for nuanced and adaptable welfare policies. [Appendix] provides further model details supporting our analysis.

# Data {#sec-data}

This paper analyzes data from the NORC General Social Survey (GSS) at the University of Chicago, specifically selecting the “welfare” dataset from 1972 to 2022. Our study mainly enable a comparison of public perceptions of welfare adequacy in the United States. We will also give examples of some specific years for analysis, including 1980, 2018, the normal economic years, and 1982, 2021, the years when recession occurred.
\break

## Source Data

To achieve the above goals, this paper filters out selected variables from selected data variables in GSS and downloads them as @tbl-raw-data-overview shown. The open source statistical programming language R [@citeR] and the libraries `tidyverse` [@tidyverse], `ggplot2` [@ggplot2], `dplyr` [@dplyr], `readr` [@readr clean data], are used in the data process. `tibble` [@tibble], `here` [@here], `kableExtra` [@kableExtra], `janitor` [@janitor] and `knitr` [@knitr].

```{r}
#| echo: false
#| tbl-cap: Overview of the Raw Data 
#| label: tbl-raw-data-overview
#| warning: false
#| message: false

# Load packages
library(knitr)
library(kableExtra)

# Read raw data
raw_data <- read.csv("~/Welfare and The Economy/data/raw_data/raw_data.csv")

# Create a table preview with only the first five columns
table_preview <- data.frame(
  Variable = names(raw_data)[1:5],
  NewName = names(raw_data)[1:5],
  Description = c("The year of the survey recorded",
                  "Unique identifier for the respondent",
                  "Respondent's attitude towards national welfare",
                  "Respondent's type of ballot",
                  "Content unclear, column unnamed")[1:5],
  Example = as.character(sapply(raw_data[1:5], function(col) col[1]))
)

# Use kable and kableExtra to create the table
kable(table_preview, "latex", row.names = FALSE, booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, font_size = 12) %>%
  column_spec(1, bold = TRUE)  # Only specify LaTeX-compatible styling
```


## Data Cleaning

There are many unclear variable names in the original dataset. In order to make the analysis clearer, we renamed the "natfare" variable name to "Response," because this variable mainly indicates the respondents' views on social welfare. Another variable used is "year". The purpose of this variable is to capture the year in which the survey was conducted. Finally, the variable contents of "ballot" and "x5" that are irrelevant to the paper were removed and at the same time, the position structure of the entire dataset was reorganized to better reflect the number of different responses each year as @tbl-cleaned-data-overview shown.

```{r}
#| warning: false
#| tbl-cap: Overview of the Cleaned Data 
#| label: tbl-cleaned-data-overview
#| message: false
#| echo: false

## Cleaned_data Preview
# Load the necessary libraries
library(tidyverse)
library(knitr)
library(kableExtra)

# Load the data
cleaned_data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Categorize and summarize the data
categorized_data <- cleaned_data %>%
  count(year, response) %>%
  spread(key = response, value = n, fill = 0) %>%
  mutate(year = as.character(year), # Convert 'year' to character to combine with the 'Total' string later
         Total = rowSums(.[,-1])) # Add a 'Total' column

# Calculate the total row
total_row <- colSums(categorized_data[,-1]) # Sum all columns except 'year'
total_row_df <- as.data.frame(t(total_row))
colnames(total_row_df) <- colnames(categorized_data)[-1] # Ensure column names match
total_row_df$year <- "Total" # Add a 'year' column with the value 'Total'

# Combine the total row with the data frame
categorized_data <- bind_rows(categorized_data, total_row_df)

# Select the top 5 rows for display
categorized_data_top5 <- head(categorized_data, 5)

# Create the table with kable and kableExtra, displaying only the top 5 rows
categorized_data_table <- categorized_data_top5 %>%
  select(year, everything()) %>% # Ensure the 'year' column is first
  kable("latex", row.names = FALSE, booktabs = TRUE) %>%  # Use LaTeX format for PDF
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(0, bold = TRUE) %>%  # Make the header row bold
  column_spec(1, bold = TRUE)  # Make the first column bold

# Print the table
categorized_data_table

```

## Survey Methodology

Between 1972 and 2018, the General Social Survey (GSS) relied primarily on face-to-face interviews to collect data. The personal interaction inherent in these interviews allows for deeper exploration of answers, including the ability to resolve unclear answers more effectively. However, due to the outbreak of the COVID-19 pandemic, the GSS adapted, shifting its data collection strategy to online surveys from 2020 to 2021 but questions became more inflexible.

Survey Audience GSS focuses on adults 18 years of age and older who live in the United States and communicate in English or Spanish [@gssCodebook2022]. We worry that despite this inclusion criterion enabled a more diverse group of participants to contribute to the survey; those who do not meet these language requirements or are still unable to participate for health reasons are excluded from the scope of the @GSS.

This paper focuses on the survey methods employed in overall years of 1972-2022, its every ten-year average and some specific years: 1980, 1982, 2018 and 2021, relevant to the years of interest in working time research. During GSS survey, participants were asked: "We face many problems in this country, none of which can be easily or cheaply solved. I will list some of them, and for each one I hope you can name some of them "For each question, I want you to tell me whether we're spending too much, too little, or the right amount?” 

The above structure of the question has remained unchanged from 1972 to 2022, ensuring the reliability of data collection and analysis over time.

## Statistical Analysis Methodology

In our study, we employ time series analysis as a way to track the evolution of public perceptions of welfare spending over longer periods. This approach allows us to carefully assess sentiment trajectories across decades and identify any significant trends or sudden changes in public perception.

We also conducted a numerical analysis to further understand public attitudes toward welfare spending. This method counts the number of responses falling into predefined categories (“too much,” “too little,” and “about right”) for each survey year. We believe the numerical analysis is the most convenient way to understand how public sentiment on welfare spending fluctuates over time as the socioeconomic landscape changes; among them, the "too little" variable is the indicator we are most concerned about because it directly represents the public's evaluation of the welfare mechanism.

Screening analyses form another key component of our statistical analysis. By classifying years according to the extreme sentiment expressed about welfare spending, we identify periods particularly salient in public opinion (e.g. unusually high levels of a certain variable). This approach allows us to isolate and examine years of significant public consensus on welfare policy and compare it to years of average economic growth to understand the potential catalysts driving these sentiments.

## Trend of Too Little Responses

In our analysis, we processed the data to distill the annual count of "too little" responses concerning welfare provisions from 1972 to 2022. We first filtered the dataset to isolate the "too little" responses. Subsequently, we aggregated these responses by year to observe the annual fluctuations. To provide a clear visual representation of the trend, we plotted these counts using a line graph, emphasizing each year's count with a distinct point.

Observing the trend in the graph @fig-too-little-trend, we note an undulating pattern of "too little" responses over the fifty-year span. The trend is characterized by significant peaks and troughs, it is notable that there are periods where the counts sharply increase, suggesting spikes in the sentiment that welfare is insufficient. Following these peaks, there are also steep declines at certain intervals, indicating a drop in the number of "too little" responses. Overall, despite these fluctuations, there is a discernible upward trend in the recent 10 years (2012-2022), culminating in a prominent peak towards the end of the period under consideration. This trend shows an increasing number of respondents perceive welfare provisions to be inadequate in more recent years.

```{r}
#| warning: false
#| fig-cap: Trend of Too Little Responses from 1972 to 2022
#| label: fig-too-little-trend
#| message: false
#| echo: false

# Load data
data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv", stringsAsFactors = FALSE)

# Filter for 'Too Little' responses
data_too_little <- subset(data, response == "Too Little")

# Calculate the count of 'Too Little' responses per year
annual_counts <- aggregate(id ~ year, data = data_too_little, FUN = length)

# Rename the column to reflect that it's a count
names(annual_counts)[2] <- "Too_Little_Count"

# Ensure the 'year' column is numeric (if it's not already)
annual_counts$year <- as.numeric(as.character(annual_counts$year))

# Select data between 1972 and 2022
annual_counts_subset <- annual_counts[annual_counts$year >= 1972 & annual_counts$year <= 2022, ]

# Load the ggplot2 package
library(ggplot2)

# Create a trend plot
ggplot(annual_counts_subset, aes(x = year, y = Too_Little_Count)) +
  geom_line(color = "blue") +  # Add a line graph
  geom_point(color = "red") +  # Add points to mark each year's data
  labs(x = "Year",
       y = "Count of 'Too Little' Responses") +
  theme_minimal()  # Use a minimal theme for a cleaner look

```


# Model

Our data analysis found trends in the “too little” category of General Social Survey responses that could indicate public perceptions of benefit adequacy. This trend corresponds to the changing economic landscape over the years, and to capture this dynamic quantitatively, we designed a linear regression model to predict the likelihood of a “too little” response depending on the year of survey. We ran the model in R [@citeR] using @rstanarm's `rstanarm` package. For comprehensive background details on model construction, variables, and diagnostics, please see the [Appendix](#sec-model-details).

The formula for our linear regression model is:


$$
\text{proportion\_too\_little}_i = \beta_0 + \beta_1 \times \text{year}_i
$$

In this model, proportion\_too\_little_i indicates the predicted proportion of "too little" responses for the i^{th} year, $\beta_0$ represents the model's intercept—the starting point on the y-axis when the year is zero, which we interpret as the survey's baseline year of 1972. The coefficient $\beta_1$ indicates the amount of change in "too little" responses we can expect with each passing year. If $\beta_1$ is positive, it supports our hypothesis of an upward trend.

## Model Justification

We posit a clear relationship between the passage of time and the rising public advocacy for more comprehensive welfare reflected in "too little" responses within the General Social Survey (GSS) data. Specifically, we hypothesize that the proportion of "too little" responses exhibits a consistent upward trend from 1972 to 2022, indicative of a growing public sentiment that government welfare provision is falling short of societal needs.

The linear regression model we propose serves to validate this hypothesis mathematically. If the coefficient $\beta_1$ to be positive will confirm our assumption of an upward trajectory for “too little” responses. As an illustrative example, suppose that the GSS data show a large increase in “too little” responses in the years following the implementation of the welfare reform policy, which would appear in our model as a steeper slope in these years.

# Results

## Analysis of Model Results
The linear model outlined in @tbl-linear-trend and visualized in the accompanying graph suggests a positive trend in the frequency of "too little" responses over the surveyed years. This trend is evidenced by the positive coefficient for 'year' ($\beta_1$ = 3.63), which suggests that each successive year is associated with a slight increase in the proportion of "too little" responses.

However, the model indicates a low R² value (0.026) suggesting that the model explains only a small fraction of the variability in the response data. This could imply that while there is a positive trend, other unaccounted factors may also significantly influence public perception of welfare adequacy.

@fig-linear-trend presents a visual representation of the trend with individual data points for each year and a superimposed linear regression line in blue. The shaded area around the regression line represents the confidence interval, providing a visual understanding of the potential variability around the estimate.

### Interpretation of the Trend
The slight upward trajectory observed in the model output [@tbl-linear-trend] can be interpreted as a growing public sentiment that welfare provision is "too little." This might reflect an overall increase in public expectations for welfare support, possibly driven by social, economic, or policy changes over time. The pattern could also indicate a responsiveness to economic conditions, with higher "too little" responses potentially following economic downturns. 

The positive trend in "too little" responses shows the importance of considering public opinion when formulating welfare policies. The increasing frequency of these responses over the years may signal a need for policymakers to re-evaluate the adequacy of welfare programs and consider reforms that align with evolving public expectations.

Despite this, it is essential to approach these results with caution given the model's low explanatory power, as indicated by the R² value in @tbl-linear-trend. While the model identifies a trend, it does not adequately capture the complexity of public opinion on welfare. This calls for a more nuanced analysis, perhaps incorporating additional variables or alternative statistical methods to better understand the sentiment about public welfare.


```{r}
#| warning: false
#| tbl-cap: Linear Model Showing the Trend of Too Little Responses
#| label: tbl-linear-model
#| message: false
#| echo: false
#| eval: true

library(tidyverse)
library(rstanarm)
library(modelsummary)

# Load the model (make sure the path is correct and use `here` if needed)
#model_path <- "~/Welfare and The Economy/models/analysis_of_the_trend_model.rds"
model_path <- "~/Welfare and The Economy/models/first_model.rds"
first_model <- readRDS(file = model_path)

model_data <- read_csv("~/Welfare and The Economy/data/analysis_data/model_data.csv")

# Print out that the model was loaded successfully for debugging purposes
# cat("Model loaded successfully from:", model_path, "\n")
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-linear-trend
#| tbl-cap: The Model Trend of Too Little Responses is Increasing Every Year

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-linear-trend
#| fig-cap: The Trend of Too Little Responses is Increasing Every Year
# Visualizing the trend
ggplot(model_data, aes(x = year, y = proportion_too_little)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue") +
  labs(x = "Year",
       y = "Proportion of 'Too Little' Responses") +
  theme_minimal()
```

## Recession Years vs. Stable Economic Years

In 1982 the United States was grappling with the effects of a severe recession that had begun the previous year; this recession was characterized by an unemployment rate of 10.8% and a shrinking gross domestic product [@brenner2003boom]. The rise in the 1982 bar represented by @fig-comparison-years may reflect rising public enthusiasm for stronger welfare support during this difficult period.

In 2021 the world, including the United States, has been significantly affected by the long-term effects of the COVID-19 pandemic; which has not only caused a public health crisis but also caused economic disruption[@bartik2020]. In @fig-comparison-years it can be seen that the "too little" response is higher in 2021 than in 1982, indicating that the public is more vocal about increasing benefits.

In comparison, 1980 and 2018 are known for more stable economic conditions. Although the recession began in 1980, the full effects were not yet felt, which may explain why the threshold was lower than in 1982. 2018 was part of a sustained period of growth following the 2008 financial crisis, with low unemployment rates and steady GDP growth. The corresponding standard in 2018 is lower than in 2021, indicating fewer responses indicating an undersupply of benefits, consistent with what would be expected in a period of economic stability.

The above confirms @GSS data expressing a significant increase in "too little" responses during difficult economic times, suggesting the public needs more welfare support when facing economic uncertainty or downturns. In contrast, during periods of stability, pressures on the welfare system appear to be less intense, as reflected in the lower number of “too few” responses.

```{r}
#| warning: false
#| fig-cap: Comparison Between 1980 and 1982, 2018 and 2021
#| label: fig-comparison-years
#| message: false
#| echo: false

## Comparison between 1980 and 1982, 2018 and 2021
library(ggplot2)
library(dplyr)
library(readr)

# Load the cleaned data
cleaned_data <- read_csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Filter data for the years and "Too Little" response
comparison_data <- cleaned_data %>%
  filter(year %in% c(1980, 1982, 2018, 2021), response == "Too Little") %>%
  count(year)

# Create the comparison graph
ggplot(comparison_data, aes(x = as.factor(year), y = n, fill = as.factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Year",
       y = "Count of 'Too Little' Responses",
       fill = "Year") +
  theme_minimal() +
  theme(legend.position = "none")  # We do not need a legend since the year is on the x-axis

```

## Trends in Too Much Responses

While the trend for "too little" responses shows a consistent upward trajectory, indicating an increasing proportion of the population who feel that welfare spending is insufficient, "too much" responses in @fig-too-much show a more complex pattern.

Historically, the number of “too much” responses has not been at a low point (1984 - 1990) in recent years; rather, it has shown an increasing trend in certain periods, especially from 2008 to 2021. This period coincided with major economic events, including the 2008 global financial crisis.

The increasing trend of “too much” responses over the years suggests that some groups are increasingly concerned about the size and scope of benefit programs; a sentiment that they do not want benefit spending to potentially exceed necessary levels.

```{r}
#| warning: false
#| fig-cap: Trends in Too Much Response from 1972 to 2022
#| label: fig-too-much
#| message: false
#| echo: false
library(ggplot2)
library(dplyr)

# Load the data
data <- read.csv('~/Welfare and The Economy/data/analysis_data/cleaned_data.csv')

# Filter for 'Too Much' responses
too_much_data <- data %>%
  filter(response == 'Too Much')

# Group by year and count the number of 'Too Much' responses
too_much_trend <- too_much_data %>%
  group_by(year) %>%
  summarise(count = n())

# Plot the trend
ggplot(too_much_trend, aes(x = year, y = count)) +
  geom_line(color = "orange") +
  geom_point(color = "red") +
  theme_minimal() +
  labs(x = 'Year',
       y = 'Count of "Too Much" Responses')

```

# Data and Model Limitations

## Data Limitations

One of the critical limitations in the Data section pertains to the data cleaning process. While we renaming variables such as "natfare" to "Response" aids in clarity, it could also mask the nuances initially captured by the survey's wording. For instance, a respondent's view on "national welfare" encompasses a broad range of descriptions of their decisions; this is beyond what we might strictly define as welfare in the cleaned data. Therefore, we risk oversimplifying complex attitudes and losing granular insights by streamlining variable names for clarity.

Additionally, while removing irrelevant variables like "ballot" and "x5" simplifies the dataset, it also eliminates data that might have contextual relevance. For example, the type of ballot used could influence how questions are perceived and answered, thereby affecting the data's integrity.

The methodology shift in the GSS from in-person interviews to online surveys introduces another layer of complication. Online surveys might exclude non-internet-savvy populations or those without reliable internet access, skewing the data towards certain demographic profiles. For instance, we assume that older adults who are less comfortable with technology might be underrepresented in the post-2020 data, potentially biasing the findings towards the attitudes of younger, more tech-savvy generations.

### Challenges Posed by Biennial Data Collection in the GSS

When collecting data, we note that the General Social Survey (GSS) collects information every two years. The above initiatives may help the GSS collection process become more accurate and avoid being too time-pressured; however, this interval of data collection may affect our analysis and comparison. For example, if a major policy change or economic event occurs within a year without a survey, we will not be able to immediately see how people react to it. Using the welfare analysis targeted at this paper as a reference, if unemployment occurs suddenly in a year for which we have no data, we cannot judge how people feel about their welfare needs during that period. Or, if the economy improves quickly and we don't have data for the current year, our next survey might show that people are okay with receiving less benefits, but we won't know exactly when they start feeling that way. Thus, when we look at our findings, we have to remember that our paper may not have enough ability to get the full picture.

We use @fig-missing-years to show two missing years, 2001 and 2020, as examples; they represent the periods of the 9/11 attacks and the COVID-19 pandemic respectively.

The lack of data for 2001 means there are gaps in capturing public sentiment at a time when the United States faced significant hardship and geopolitical instability. This period could influence views on a range of issues from national security to immigration and foreign policy. Without this year's data, the analysis could miss changes in public opinion that could have long-term consequences.

Likewise, gaps in the 2020 GSS data present obstacles to analyzing public opinion on welfare during a critical period. Without insights from this year, we cannot fully understand how the pandemic’s immediate economic shock may have changed welfare expectations. In 2020, job losses surged and demand for government assistance surged. Without data for this period, we miss key information about whether people believe existing benefits are adequate to survive the crisis.

In both cases, we argue that the lack of data limits researchers' ability to conduct informed analyzes of the temporal dynamics of public opinion. It also hinders assessment of the long-term impact of these events on social trends.

```{r}
#| warning: false
#| fig-cap: There are Major Social Events in Some Missing Years 
#| label: fig-missing-years
#| message: false
#| echo: false

# Load necessary libraries
library(ggplot2)
library(dplyr)

# Load the data
data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Assuming GSS collects data every two years, generate all years within the range
all_years <- seq(from = 1972, to = 2022, by = 1)

# Manually specified years and corresponding major events
specified_years <- c(1980, 1990, 2001, 2008, 2020)
specified_events <- c("Recession Begins", "Policy Change", "9/11 Impact", "Financial Crisis", "COVID-19 Pandemic")

# Create a dataframe for the specified years and events
events_df <- data.frame(
  Year = specified_years,
  Event = specified_events
)

# Determine which years data was actually collected
# For simplicity, we assume that if the GSS data collection started in an even year,
# then all even years have data collected and odd years are missing.
data_collected_years <- data %>%
  select(year) %>%
  distinct() %>%
  pull()

# Now determine the missing years
missing_years <- setdiff(all_years, data_collected_years)

# Filter to only include missing years that had major events
missing_events_df <- events_df %>%
  filter(Year %in% missing_years)

# Create the plot for missing years and their events
ggplot(missing_events_df, aes(x = factor(Year), y = 1, fill = Event)) +
  geom_col() +
  geom_text(aes(label = Event, y = 1.05), color = "black", size = 3.5, vjust = 0) +
  scale_x_discrete(name = "Year") +
  scale_y_continuous(name = "", labels = NULL, breaks = NULL) +
  labs(fill = "Event") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        plot.title = element_text(hjust = 0.5),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "bottom")

```

### Concerns about Inconsistent Response Rates

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: Annual Trends Show Inconsistent Total Response Rates
#| label: fig-trends-response

# Calculate the total responses per year
total_responses_per_year <- cleaned_data %>%
  group_by(year) %>%
  summarise(total_responses = n())

## Trends in Public Opinion Over Time in The US
ggplot(total_responses_per_year, aes(x = year, y = total_responses)) +
  geom_line(color = "#2C3E50", size = 1) +
  geom_point(color = "#E74C3C", size = 3, shape = 18) +
  theme_minimal(base_size = 14) +
  labs(x = "Year",
       y = "Total Responses",) +
  theme(plot.title = element_text(hjust = 0.5))

```

@fig-trends-response provided displays the annual trend of total responses from the General Social Survey (GSS). We find a noticeable fluctuation in the number of responses over the years; these inconsistencies raise concerns about the dataset's stability and reliability, which could influence the robustness of any analyses conducted using this data.

The peaks and troughs in the graph could suggest varying levels of engagement or interest in the survey across different years. For example, there was a significant dip around the early 1990s. Conversely, there has been a sharp increase in recent years, such as the noticeable peak in 2020.

For a researcher, these inconsistencies could complicate trend analysis. If the number of responses is not consistent, it's challenging to determine whether changes in the data are due to actual shifts in public opinion or simply the result of varying sample sizes. Similarly, a sudden increase in responses might overemphasize concerns that are not as pressing across the broader population.

### Rising ‘Inapplicable’ Responses

Among other things, we examine trends in “not applicable” responses in the GSS dataset over a 50-year period from 1972 to 2022. We made @tbl-average-inapplicable to complement this finding by providing a detailed breakdown of average counts per decade. The average number reached its highest level in the 1970s, with an average of 1,613 “not applicable” responses. There was a significant decline in the 1980s, with an average of 875.67. However, the trend for "not applicable" responses climbed again in subsequent decades, reaching a second peak in the 2020s with an average of 1904.50.

The visual representation provided by @fig-inapplicable-years illustrates a fluctuating but overall increasing trend in the average number of “not applicable” responses per decade. This increase has been particularly pronounced in the most recent decade (the 2020s), which we believe may indicate changes over time in survey design or the applicability of questions to survey populations. These questions may not be applicable to all respondents and may need to be better optimized to obtain more voluntary response ideas from the public.

```{r}
#| warning: false
#| fig-cap: Trend of Average Inapplicable Responses Per Decade is increasing
#| label: fig-inapplicable-years
#| message: false
#| echo: false

library(ggplot2)
library(dplyr)

# Read the dataset
raw_data <- read.csv('~/Welfare and The Economy/data/raw_data/raw_data.csv')

# Filter for 'Inapplicable' responses in the 'natfare' column
inapplicable_responses <- raw_data %>%
  filter(natfare == '.i:  Inapplicable')

# Calculate the total count of 'Inapplicable' responses per year
yearly_inapplicable_counts <- inapplicable_responses %>%
  group_by(year) %>%
  summarise(inapplicable_count = n())

# Calculate the average Inapplicable count per decade
yearly_inapplicable_counts$decade <- (yearly_inapplicable_counts$year %/% 10) * 10
decade_inapplicable_averages <- yearly_inapplicable_counts %>%
  group_by(decade) %>%
  summarise(average_inapplicable = mean(inapplicable_count))

# Create the trend graph
ggplot(decade_inapplicable_averages, aes(x = decade, y = average_inapplicable)) +
  geom_line(group = 1, color = 'blue') +
  geom_point(color = 'red') +
  labs(x = 'Decade',
       y = 'Average Count of "Inapplicable" Responses') +
  theme_minimal()

```
\break
```{r}
#| warning: false
#| tbl-cap: Average Numbers of Inapplicable Responses Per Decade
#| label: tbl-average-inapplicable
#| message: false
#| echo: false

library(knitr)
library(kableExtra)

decade_averages <- data.frame(
  Decade = c(1970, 1980, 1990, 2000, 2010, 2020),
  'Average_Count' = c(1613.00, 875.67, 1110.67, 1654.20, 1172.00, 1904.50)
)

# Generate a table with 'kable' and specify the column names for better formatting
kable(
  decade_averages,
  col.names = c('Decade', 'Average Count of Inapplicable Responses'),
  align = 'c',
  digits = 2
) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

## Model Limitations
The Model section introduces a linear regression model to predict the probability of a "too little" response based on the survey year. While the model's simplicity is a strength, it's also a limitation. The assumption that the relationship between time and perception of welfare adequacy is linear does not account for the complexities of socioeconomic factors. For example, policy changes, like the welfare reform of the 1990s, could have nonlinear effects on public opinion that a simple linear model would not capture [@blank2005did].

The low R² value indicates that the year alone is not a strong predictor of the perception of welfare adequacy, suggesting that critical variables may be missing from the model. Other potential predictors, such as unemployment rates, economic growth indicators, or significant political events, are not included in the model but could provide additional explanatory power. For example, a year with significant job growth might see a disproportionate decrease in "too little" responses, which would not be accounted for by the year alone.

Overall the model's predictive power is limited to the data range from 1972 to 2022. It may not accurately forecast future trends, especially in the face of unprecedented events such as the COVID-19 pandemic. The 2021 spike in "too little" responses could be an outlier due to the pandemic's unique economic impact, which a model based on past data might not predict accurately.

# Discussion

Through GSS data, we find that the economic downturn will lead to the public's willingness to ask for more welfare support from the government, and through model analysis, we find that the public's willingness to ask for welfare has generally increased since 1972; this indicates that the world economy may be deteriorating.

## Economic Downturns and Heightened Welfare Needs {#sec-first-point}

During periods of economic downturns, public dependency on welfare systems intensifies markedly. The previous analysis of General Social Survey (GSS) data from the past fifty years reveals that economic recessions are consistently accompanied by a rise in the proportion of the populace advocating for "too little" government welfare provision. This correlation underscores the heightened need for welfare during times when economic conditions worsen, as individuals and families face increased financial insecurity. 

In the Journal of Economic Perspectives, [@Moffitt2021] articulates that the demand for welfare support tends to surge during economic downturns as unemployment rates climb and household incomes falter. They argue that welfare systems are not merely safety nets but essential frameworks for economic stabilization, suggesting that robust welfare support during downturns mitigates immediate financial distress and aids in broader economic recovery.

## Welfare Demand Disparities Across Demographics in Recessions

Nonetheless, based on different academic studies, we realize that the pursuit of welfare support during recessions shows significant differences across different demographic groups, particularly by income level. The wealthy generally remain more financially stable during recessions and therefore experience smaller increases in welfare needs; this explains why in @fig-too-much we can see that in many years despite recession there is still a sizable group that disapproves of increased government spending on welfare. In contrast, lower-income groups tend to be more vulnerable to economic fluctuations and therefore more likely to seek additional government support during this period as @tbl-linear-trend shown.

Research by @Hacker2010 discusses how low-income individuals were disproportionately affected by the economic downturn, causing their welfare needs to increase significantly compared to those with higher incomes. These individuals often face higher risks of unemployment, reduced work hours, and greater challenges in meeting basic needs. Retail workers provide a stark example of vulnerability. Retail workers, who are typically non-managerial workers and low- to moderate-income earners, are highly vulnerable to economic downturns due to their reliance on consumer spending and limited job security, which exacerbates their dependence on benefits. In another perspective, @Chetty2018 provides evidence that economic recessions severely impact low-income populations, manifested by increased applications for unemployment benefits and other welfare services. Their analysis highlights that income-related welfare demand elasticities are particularly pronounced during economic crises, suggesting that welfare demand is more responsive among low-income groups.

The simultaneous increase in “too little” and “too much” responses may reflect polarized views on welfare, with the public increasingly divided. This polarization may be due to people's different economic experiences, different political ideologies, and the influence of the media on public opinion.

## Policy Implications for Welfare Support During Economic Downturns

Through the above analysis, we know that there are obvious differences in the welfare needs of different population groups during the economic recession, and nuanced policy interventions are needed. This section outlines targeted recommendations for improving the effectiveness of welfare policies, supported by academic research.

First, governments could be encouraged to implement progressive welfare programs that dynamically increase support based on the severity of economic need. This approach aims to provide a safety net that responds to changes in personal financial circumstances, which is crucial during economic downturns, particularly for low-income groups who are disproportionately affected, to ensure that society does not further increase the risk of insecurity. equality. Temporary Assistance to Needy Families (TANF) is a good real-life example of a progressive welfare program. Increasing aid amounts and relaxing eligibility criteria during a recession can have a significant impact on those on the edge of poverty. Research conducted by [@edin2015] shows that modifications to TANF benefits are effective in providing critical support to vulnerable populations, so such adjustments to benefit programs could prevent the poorest from suffering the worst consequences of the economic downturn.

The government should further pursue flexible welfare eligibility standards in society. During economic downturns, lowering the eligibility threshold for welfare programs can prevent many people from falling into serious difficulties. [garthwaite2014] Explains the Medicaid expansion under the Affordable Care Act (ACA) by relaxing criteria to include more individuals at risk of losing health insurance. The benefits of such an adaptable benefit standard would be to meet growing needs during recessions and ensure that a larger proportion of the population is still covered during critical periods.

## Ethical Considerations

Valid ethical considerations should be considered when conducting research on sensitive topics such as public welfare concepts. Ensuring the confidentiality and anonymity of survey respondents is critical to protecting their privacy and encouraging honest and unbiased responses. For example, using an encrypted data storage solution can protect sensitive information from unauthorized access. To minimize harm, obtaining informed consent is a key practice that must be strictly adhered to.

We believe it is also critical to address potential biases that may distort study results. We therefore suggest that employing strategies such as stratified sampling can help achieve a representative distribution of the population, thereby minimizing the risk of over- or under-representation of any particular group.

## Limitations

While these journals provide authoritative insights, this paper is unable to provide specific data examples from the @GSS itself, resulting in a theoretical rather than an empirical discussion of population differences. We also believe that this reliance introduces secondary interpretation that may diminish the straightforwardness of GSS data analysis.

Additionally, the paper synthesizes academic research to provide policy implications and, while academic in nature, may not fully capture current welfare realities or encompass the diversity of the American population. Without integrating raw population-specific data from GSS, the resulting generalizations may lack the granularity needed to effectively tailor policy recommendations to the nuanced needs of different population groups.

The ethical considerations discussed in the paper also fail to demonstrate how these considerations are implemented in the research methodology. While we believe that the importance of ethics in research is rightly emphasized, a detailed description of the ethical protocols followed in the study must be explored in light of the specific research process.


## Proposed Next Steps for Future Research

To enhance future research on public welfare perceptions and overcome the limitations identified in this study, we propose here several focused research initiatives. First, enriching the dataset with detailed demographic information, such as specific income brackets and broad benefit coverage, will allow for a nuanced analysis of how different groups are affected by economic conditions. Qualitative data combined with interviews and quantitative surveys can also provide a deeper understanding of personal experiences and expectations.

We suggest that @GSS can employ hybrid methods, such as combining large-scale survey data with focus groups, which can provide comprehensive insights and overcome the limitations of traditional surveys, particularly in capturing the sentiments of marginalized or underrepresented groups. In response to rapid changes in public opinion during economic fluctuations, implementing continuous or more frequent data collection would provide policymakers with timely data.

For welfare analysis, conducting longitudinal studies that track individuals over time would reveal the long-term effects of welfare policy changes and economic cycles on individual and household welfare perceptions. Before implementing new welfare policies, simulation studies based on predictive models can predict outcomes and help fine-tune policies to better meet public needs and minimize adverse impacts. These steps to enhance data richness and methodological robustness will ensure that future research is more reflective of complex social dynamics and better able to inform effective welfare policy.

# Conclusion

This paper uses data from the U.S. General Social Survey (GSS) to analyze public perceptions of welfare adequacy in the context of different economic conditions from 1972 to 2022. Our aim is to determine whether economic recession affects public demand for increased government benefits and how these demands differ across demographic groups. Our findings confirm that calls for more welfare support do increase during recessions, particularly among low-income groups, highlighting the need for policy to be responsive to economic cycles.

However, the study faced limitations due to the @GSS methodology, so future research should consider using more frequent and methodologically consistent data collection to increase the reliability of findings. Additionally, exploring more granular demographic data could provide a deeper understanding of how economic conditions affect different groups of people differently.

Therefore, we advocate a proactive approach to policy planning, including continuous monitoring of economic trends and public welfare needs to ensure that welfare provision can fully reflect economic realities and public opinion in the future.

\newpage

\appendix

# Appendix {-}

# Model Details {#sec-model-details}

## Posterior Predictive Check

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining How the Model Fits, and is Affected by, the Data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]


pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics
```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the Convergence of the MCMC Algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage


# References


