---
title: "Welfare Expectations Across U.S. Economic Cycles"
subtitle: "Analysis of the the American public's views on government provision of benefits under different economic conditions over the past 50 years"
author: 
  - Tianen (Evan) Hao
thanks: "Code and data are available at: https://github.com/ShadyEvan4830/Welfare_Expectations_and_The_Economy.git. Links marked high-contrast 1:5 ratio green by Professor Alexander in lecture."
date: March 31, 2024
date-format: long
abstract: "A country's economic conditions often influence public perceptions of government welfare practices. However, do all citizens truly meet the general expectation of higher welfare during economic downturns and higher welfare during economic boom? Using data from the General Social Survey (GSS) Welfare, this paper examines whether the American public believes government welfare initiatives over the past 50 years have been adequate, particularly under different economic circumstances. Our analysis shows that there are widespread public calls to reduce welfare spending during good times, while in bad times, this leads to a stronger demand for government assistance. Despite this trend, differences in welfare expectations remain evident between different demographic groups, such as high- and low-income groups. This finding highlights the need for society to develop welfare policies for different groups and provide a basis for creating fairer and more sensitive welfare strategies amid economic fluctuations."
format: pdf
toc: true
number-sections: true
bibliography: bibliography.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#download the packages if necessary, then load the packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(janitor,here,dplyr,tidyverse,knitr,kableExtra,ggplot2)

library(janitor)
library(tidyverse)
library(knitr)
library(dplyr)
library(kableExtra)
library(here)
library(ggplot2)
```

# Introduction {#sec-intro}

Public attitudes towards government welfare programs fluctuate with economic conditions, swinging from calls for austerity during prosperous times to demands for increased support in downturns. This study investigates whether there's a consistent trend of advocating for reduced welfare spending in periods of economic prosperity, driven by beliefs in self-reliance and economic opportunity and whether there's a noticeable shift towards supporting more government welfare provisions during downturns, as seen during the 1982 recession, the 2008 Global Financial Crisis, and the 2020 COVID-19 pandemic. Importantly, we explore whether this trend is consistent across all public segments or if attitudes vary among different demographic groups.

This paper uses nearly 50 years of welfare data from the General Social Survey (GSS) to study the U.S. economic situation and public perceptions of welfare adequacy. We analyze public opinion primarily during periods of growth, stability, and recession to identify overall trends in welfare perceptions and their impact on demographics defined by income and employment status.

We hypothesize that the public expects more benefits when the economy is low and fewer benefits when the economy is growing. Our preliminary findings reveal that public opinion is actually multifaceted. The recession significantly affected demand for increased government welfare action but with significant differences across demographic groups.

These findings have profound implications, indicating that a one-size-fits-all approach to welfare policy may not meet the diverse needs of the population effectively. Our research points to the benefits of developing welfare policies that are more responsive and tailored to the varied expectations and needs across the societal spectrum.

The structure of this paper starts with the current [Introduction] to explain the overall logic and content. The subsequent [Data] section outlines our methods and data-cleaning efforts, laying the foundation for our analysis. In the [Results] section, we present findings on public welfare perceptions under different economic conditions. [Discussion] These findings are interpreted within the larger context of welfare policy and public expectations and are expected to trigger reflections on the limitations of the study and potential directions for future research. Finally, we synthesize our main insights in [conclusion] to highlight the urgent need for nuanced and adaptable welfare policies. [Appendix] provides further data and survey details supporting our analysis.

(Evan Hao dreamed about Rohan last night, reminding Evan needed to do a lot cross-reference and graphs/tables later)

# Data {#sec-data}

This paper analyzes data from the NORC General Social Survey (GSS) at the University of Chicago, specifically selecting the “welfare” data set from 1972 to 2024. The study enables a comparison of public perceptions of welfare adequacy in different economies. These include 1982, the 2008 global recession and the 2020 recession triggered by the COVID-19 pandemic.
\break

## Source Data

This paper filters out selected variables from selected data variables in GSS and downloads them as @tbl-raw-data-overview shown. The open source statistical programming language R [@citeR] and the libraries `tidyverse` [@tidyverse], `ggplot2` [@ggplot2], `dplyr` [@dplyr], `readr` [@readr clean data], are used in the data process. `tibble` [@tibble], `here` [@here], `kableExtra` [@kableExtra], `janitor` [@janitor] and `knitr` [@knitr].

```{r}
#| echo: false
#| tbl-cap: Overview of the Raw Data 
#| label: tbl-raw-data-overview
#| warning: false
#| message: false

# Load packages
library(knitr)
library(kableExtra)

# Read raw data
raw_data <- read.csv("~/Welfare and The Economy/data/raw_data/raw_data.csv")

# Create a table preview with only the first five columns
table_preview <- data.frame(
  Variable = names(raw_data)[1:5],
  NewName = names(raw_data)[1:5],
  Description = c("The year of the survey recorded",
                  "Unique identifier for the respondent",
                  "Respondent's attitude towards national welfare",
                  "Respondent's type of ballot",
                  "Content unclear, column unnamed")[1:5],
  Example = as.character(sapply(raw_data[1:5], function(col) col[1]))
)

# Use kable and kableExtra to create the table
kable(table_preview, "latex", row.names = FALSE, booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, font_size = 12) %>%
  column_spec(1, bold = TRUE)  # Only specify LaTeX-compatible styling
```


## Data Cleaning

There are many unclear variable names in the original data set. In order to make the analysis clearer, we renamed the "natfare" variable name to "Response," because this variable mainly indicates the respondents' views on social welfare. Another variable used is "year". The purpose of this variable is to capture the year in which the survey was conducted. Finally, the variable contents of "ballot" and "x5" that are irrelevant to the paper were removed and at the same time, the position structure of the entire dataset was reorganized to better reflect the number of different responses each year as @tbl-cleaned-data-overview shown.

```{r}
#| warning: false
#| tbl-cap: Overview of the Cleaned Data 
#| label: tbl-cleaned-data-overview
#| message: false
#| echo: false

## Cleaned_data Preview
# Load the necessary libraries
library(tidyverse)
library(knitr)
library(kableExtra)

# Load the data
cleaned_data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Categorize and summarize the data
categorized_data <- cleaned_data %>%
  count(year, response) %>%
  spread(key = response, value = n, fill = 0) %>%
  mutate(year = as.character(year), # Convert 'year' to character to combine with the 'Total' string later
         Total = rowSums(.[,-1])) # Add a 'Total' column

# Calculate the total row
total_row <- colSums(categorized_data[,-1]) # Sum all columns except 'year'
total_row_df <- as.data.frame(t(total_row))
colnames(total_row_df) <- colnames(categorized_data)[-1] # Ensure column names match
total_row_df$year <- "Total" # Add a 'year' column with the value 'Total'

# Combine the total row with the data frame
categorized_data <- bind_rows(categorized_data, total_row_df)

# Select the top 5 rows for display
categorized_data_top5 <- head(categorized_data, 5)

# Create the table with kable and kableExtra, displaying only the top 5 rows
categorized_data_table <- categorized_data_top5 %>%
  select(year, everything()) %>% # Ensure the 'year' column is first
  kable("latex", row.names = FALSE, booktabs = TRUE) %>%  # Use LaTeX format for PDF
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(0, bold = TRUE) %>%  # Make the header row bold
  column_spec(1, bold = TRUE)  # Make the first column bold

# Print the table
categorized_data_table

```

## Survey Methodology

Between the years 1972 and 2018, the General Social Survey (GSS) primarily relied on in-person interviews for gathering data. The personal interaction inherent in these interviews allowed for a deeper exploration of responses, including the ability to address unclear answers more effectively. This traditional approach was considered highly effective for in-depth data gathering. However, due to the onset of the COVID-19 pandemic, the GSS adapted by shifting its data collection strategy to online surveys from 2020 through 2021.

The GSS focuses on engaging adults who are 18 years or older and communicate in English or Spanish, residing within the United States [@GSS]. This broad inclusion criterion enables a diverse group of participants to contribute to the survey. Yet, those who do not meet these language requirements or are unable to participate due to health reasons are excluded from the GSS's scope [@GSS].

Changes in how respondents were chosen for the GSS, including alterations to the Kish grid method, could potentially skew the representation of certain demographic groups. Moving to an online survey method might also lead to underrepresentation of older individuals, who may not be as digitally literate. This shift is significant as it could impact the understanding of labor trends among older adults, including stable employment and the challenges of age discrimination, which are vital for analyzing labor market trends comprehensively.

The focus of this review is on the survey methodologies employed during specific years: 1980, 1982, 2018, and 2021, correlating with the years of interest for the study of work hours. Participants were asked: "We are faced with many problems in this country, none of which can be solved easily or inexpensively. I'm going to name some of these problems, and for each one I'd like you to name some of these problems, and for each one I'd like you to tell me whether you think we're spending too much money on it, too little money, or about the right amount. First for welfare . . . are we spending too much, too little, or about the right amount on welfare?” The question's structure was consistently maintained from 1972 through 2022, ensuring the reliability of data collection and analysis over time. This consistency was crucial for achieving a thorough and consistent evaluation of the data, which included various modes of survey responses such as in-person, telephone, and web-based submissions.

## Statistical Analysis Methodology

In our study, we implemented time-series analysis as a core technique to trace the evolution of public opinions on welfare spending over an extended period. This method allowed us to meticulously map out and evaluate the trajectory of sentiments across decades, identifying any significant trends or sudden shifts in public perception. By analyzing the data as a series of time-ordered points, we were able to discern patterns such as cyclicality or trends corresponding to economic, political, or social events impacting public sentiment towards welfare policies.

To further our understanding of the public's stance on welfare expenditure, we conducted a proportion analysis. This approach involved calculating the percentage of responses falling into predefined categories ('Too Much', 'Too Little', 'About Right') for each survey year. The proportion analysis facilitated a nuanced comparison across different periods, revealing how public sentiment towards welfare spending has fluctuated in response to changes in the socio-economic landscape. It also allowed us to gauge the intensity of public opinion and its alignment or divergence from policy shifts over time.

Ranking and sorting constituted another pivotal component of our statistical analysis. By categorizing years based on the extremity of sentiments expressed towards welfare spending, we pinpointed periods that stood out due to particularly pronounced public opinions. This method enabled us to isolate and scrutinize years with significant public consensus or discontent regarding welfare policies, offering insights into potential catalysts driving these sentiments and their implications on policy and societal norms.

## Potential issues with the two-year collection gap in the GSS dataset

When collecting data, we note that the General Social Survey (GSS) collects information every two years. The above initiatives may help the GSS collection process become more accurate and avoid being too time-pressured; however, this interval of data collection may affect our analysis and comparison. For example, if a major policy change or economic event occurs within a year without a survey, we won't be able to immediately see how people react to it. It's like trying to follow a story but missing all the other chapters. Using the welfare analysis targeted at this paper as a reference, if unemployment occurs suddenly in a year for which we have no data, we cannot judge how people feel about their welfare needs during that period. Or, if the economy improves quickly and we don't have data for the current year, our next survey might show that people are okay with receiving less benefits, but we won't know exactly when they start feeling that way. So when we look at our findings, we have to remember that we may not get the full picture.

## Recession Years vs. Stable Economic Years

```{r}
#| warning: false
#| fig-cap: Comparison between 1980 and 1982, 2018 and 2021
#| label: fig-comparison-years
#| message: false
#| echo: false

## Comparison between 1980 and 1982, 2018 and 2021
library(ggplot2)
library(dplyr)
library(readr)

# Load the cleaned data
cleaned_data <- read_csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Filter data for the years and "Too Little" response
comparison_data <- cleaned_data %>%
  filter(year %in% c(1980, 1982, 2018, 2021), response == "Too Little") %>%
  count(year)

# Create the comparison graph
ggplot(comparison_data, aes(x = as.factor(year), y = n, fill = as.factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Comparison of 'Too Little' Responses in Selected Years",
       x = "Year",
       y = "Count of 'Too Little' Responses",
       fill = "Year") +
  theme_minimal() +
  theme(legend.position = "none")  # We do not need a legend since the year is on the x-axis

```

In 1982, the United States grappled with the ramifications of a severe recession that began in the previous year. This downturn was marked by high unemployment, reaching up to 10.8%, and a contraction in the GDP. The elevated bar for 1982 in the graph possibly reflects a heightened public sentiment for more robust welfare support during this trying time.

Moving to 2021, this year was significantly affected by the long-term impacts of the COVID-19 pandemic, which not only caused a public health crisis but also resulted in economic disruptions. Stimulus measures and government support were critical aspects of the economic response. The even higher bar for 2021 than for 1982 may suggest an even greater call from the public for increased welfare, likely influenced by the immediate economic shocks and the pandemic's uncertain long-term outcomes.

Contrastingly, the years 1980 and 2018 are known for more stable economic conditions. In 1980, despite the beginning of a recession, the full impact had not yet been felt, potentially explaining why the bar is lower compared to 1982. The year 2018 is part of a period of sustained growth following the 2008 financial crisis, with lower unemployment rates and a steadily growing GDP. The corresponding bar for 2018 is lower than 2021, indicating fewer responses suggesting that welfare provision was inadequate, aligning with expectations for periods of economic stability.

This visual comparison underscores the interplay between economic conditions and public welfare perceptions. The marked increase in "Too Little" responses during years of economic hardship points to a public demand for greater welfare support when facing economic uncertainty or downturns. Conversely, during stable periods, the pressure on welfare systems appears to be perceived as less intense, reflective in the lower number of "Too Little" responses. The stark contrast between these periods emphasizes the role economic health plays in shaping public opinion on welfare adequacy.

## Concerns about Inconsistent Response Numbers

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

# Calculate the total responses per year
total_responses_per_year <- cleaned_data %>%
  group_by(year) %>%
  summarise(total_responses = n())

## Trends in Public Opinion Over Time in The US
ggplot(total_responses_per_year, aes(x = year, y = total_responses)) +
  geom_line(color = "#2C3E50", size = 1) +
  geom_point(color = "#E74C3C", size = 3, shape = 18) +
  theme_minimal(base_size = 14) +
  labs(title = "Trend of Total Responses per Year",
       x = "Year",
       y = "Total Responses",
       caption = "Annual trend showing the total number of responses") +
  theme(plot.title = element_text(hjust = 0.5))

```

(Evan Hao dreamed about Rohan last night, reminding him that he needed to do a cross-reference) The graph provided displays the annual trend of total responses from the General Social Survey (GSS). Upon examination, there's a noticeable fluctuation in the number of responses over the years. These inconsistencies raise concerns about the stability and reliability of the dataset, which could influence the robustness of any analyses conducted using this data.

The peaks and troughs in the graph could suggest varying levels of engagement or interest in the survey across different years. For example, the significant dip around the early 1990s could indicate external factors that might have affected participation rates, such as social or political events. Conversely, the sharp increase in recent years, such as the noticeable peak in 2020, might reflect heightened public interest in welfare issues, perhaps spurred by the COVID-19 pandemic's economic impact.

For a researcher, these inconsistencies could complicate trend analysis. If the number of responses is not consistent, it's challenging to determine whether changes in the data are due to actual shifts in public opinion or simply the result of varying sample sizes. For instance, a lower number of total responses in a given year could artificially deflate the perceived importance of welfare issues if not properly accounted for in the analysis. Similarly, a sudden increase in responses might overemphasize concerns that are not as pressing across the broader population.

When using this data, it's essential to consider these variations and apply statistical techniques that can mitigate their impact. This might include weighting responses to balance out the differences or conducting sensitivity analyses to ensure that the observed trends are not artifacts of the data collection process.


# Model

In order to better analyze the trend, we analyzed the trend of replying to "Too Little" through the model. . . The structure shows that the trend has been rising in the past 50 years.
The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the linear analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model Set-up

Will update later.

### Model Justification

Will update later.

# Data Limitations

Will update later.

# Results

Will update later.

```{r}
#| warning: false
#| tbl-cap: Linear model showing the trend of Too Little responses
#| label: tbl-linear-model
#| message: false
#| echo: false
#| eval: true

library(tidyverse)
library(rstanarm)
library(modelsummary)

# Load the model (make sure the path is correct and use `here` if needed)
#model_path <- "~/Welfare and The Economy/models/analysis_of_the_trend_model.rds"
model_path <- "~/Welfare and The Economy/models/first_model.rds"
first_model <- readRDS(file = model_path)

too_little_data <- read_csv("~/Welfare and The Economy/data/analysis_data/too_little_data.csv")

# Print out that the model was loaded successfully for debugging purposes
# cat("Model loaded successfully from:", model_path, "\n")

```


```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-lalalala
#| tbl-cap: Linear model showing the trend of Too Little responses

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
# Visualizing the trend
ggplot(too_little_data, aes(x = year, y = proportion_too_little)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Trend of 'Too Little' Responses Over Years",
       x = "Year",
       y = "Proportion of 'Too Little' Responses",
       caption = "Linear model showing the trend of 'Too Little' responses") +
  theme_minimal()

```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

# Load cleaned data
cleaned_data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Calculate the total number of responses per year
total_responses_per_year <- cleaned_data %>%
  group_by(year) %>%
  summarise(total = n())

# Calculate the number and proportion of "Too Much" responses per year
too_much_proportion <- cleaned_data %>%
  filter(response == "Too Much") %>%
  count(year) %>%
  rename(num_responses = n) %>%
  inner_join(total_responses_per_year, by = "year") %>%
  mutate(proportion = num_responses / total) %>%
  arrange(desc(proportion))
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

## Years Ranked by the Highest Proportion of "Too Little" Responses
library(tidyverse)

# Load cleaned data
cleaned_data <- read.csv("~/Welfare and The Economy/data/analysis_data/cleaned_data.csv")

# Assuming cleaned_data has a 'response' column where 'Too Little' responses are indicated
# Calculate the proportion of 'Too Much' responses for each year
too_much_proportion <- cleaned_data %>%
  filter(response == "Too Little") %>%
  count(year) %>%
  mutate(total_responses = sum(n), proportion = n / total_responses) %>%
  select(year, proportion)
```



# Discussion

Will update later.

## First discussion point {#sec-first-point}

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

# Conclusion

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]


pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics
```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage


# References


